---
layout:     post
title:      "记录一次MongoDB IO异常问题"
date:       2022-07-18
author:     "perl"
header-img: "img/post-bg-e2e-ux.jpg"
lang: en
tags:
  - MongoDB
  - 数据库
---


#### MongoDB集群架构：


``` 
   三台服务器：三副本+三分片部署方案
   MongoDB 版本：4.2.20
```

#### 问题现象：

    再一次升降配后其中一条服务器磁盘读IO指标很高，然而降配后DBA离职了，之后这个问题还导致了一次线上故障，影响了比较长时间，后来业务量下来后自动恢复了，当业务量上来后很可能会再次爆发。  然后自己搭建了个MongoDB环境开始排查线上这个问题。

#### 监控截图：
     磁盘是SSD性能比较好，如果是SATA服务已经瘫了。

![图片](/img/01.png)

#### 排查过程：
   问题是降配后出现的，这个分片不均
  1.查看分片主分片分布正常，MongoDB默认读写均使用的主分片。

``` 
Rep1   10.0.0.13:10001  PRIMARY    10.0.0.14:10001  SECONDARY
Rep2   10.0.0.14:10002  PRIMARY    10.0.0.15:10002   SECONDARY
Rep3   10.0.0.15:10003  PRIMARY    10.0.0.13:10003   SECONDARY 
```

2.确认分片数据分布均匀

![图片](/img/02.png)

3.确认Hash算法（使用的userid这个也没问题）

4.索引问题？

5.副本同步问题？

这时问题出现了僵局，开始去详细看监控指标看是否能发现蛛丝马迹，同时也去翻阅MongoDB写入/查询原理。

下图是相关监控指标：

从降配后读IO一直居高不下，而网络指标却和之前没什么变化

![图片](/img/03.png)

![图片](/img/04.png)

MongoDB的查询读写机制，默认使用的是WiredTiger存储引擎
![图片](/img/06.png)


![图片](/img/07.png)

#### 问题确认

依据上面两个问题推断出问题很可能处在缓存上

     开始排查每台节点缓存使用情况，果然在IO高的节点上buff/cache缓存可用不到其他节点的三分之一，同时WT引擎分配的内存比其他节点都高。查看配置文件 WiredTiger申请内存占总内存的90%（配置估计降配后DBA把这个参数给遗漏了）


由此推断出是缓存不足导致查询直接读写磁盘导致IO被几乎打满。

开始逐步降低WiredTiger申请内存。

还好MongoDB支持动态修改，否则还需要在晚上重启服务才能验证

最终调整参数调整值官方默认值IO降了下来(我们这是两个分片在一个机器，在原有计算值上再除以2），在磁盘IO恢复后第二天业务流量突然来了一波，躲过了此劫图片，后联系开发确认是什么接口在大量查询写入，开发也很给力第二天就修复了此BUG。

![图片](/img/08.png)



``` 
db.adminCommand({setParameter: 1, wiredTigerEngineRuntimeConfig: "cache_size=XXG"})
```

总结避免再次踩坑：

 1.    WiredTiger cache，而非mongod进程的内存用量上限。MongoDB同时使用WT cache和文件系统cache，WT cache_size相对于物理内存总量不要设置的太满，需要留有一定内存为操作系统所用，若缓存不够用会直接去从磁盘读取数据导致查询性能下降，甚至服务不可用。

2.    服务升降配需要注意服务器参数，需要跟着服务器资源变动修改对应参数。

3.    排查问题需要注意到各个细节，一个很小的细节能改变排查思路。

公众号
![图片](/img/sunpear.png)

